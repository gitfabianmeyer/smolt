{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85698f79",
   "metadata": {},
   "source": [
    "# Welcome to the <span style=\"color:blue\">Statistical Methods of Language Technologyb SoSe21</span> course\n",
    "###  Dr. Seid Muhie Yimam\n",
    "   * Email: yimam@informatik.uni-hamburg.de\n",
    "   * Office: Informatikum, F-415\n",
    "  \n",
    "###  Dr. Özge Alaçam\n",
    "   * Email: alacam@informatik.uni-hamburg.de\n",
    "   * Office: Informatikum, F-435"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751371f",
   "metadata": {},
   "source": [
    "## Topic of this week;\n",
    "In this first practice class, we are going to focus on two main topics, which will be useful to complete the assignment;\n",
    "* POS HMM\n",
    "* CRF\n",
    "\n",
    "\n",
    "## Deadline: 19/24 May\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8c031",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> In class Exercises </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce0f84",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Problem 5.1 POS HMM </span>\n",
    "\n",
    "### a) Train a POS HMM with MLE estimation, using the annotated text: \n",
    "\n",
    "```\n",
    "the/D cat/N can/VA fish/VV a/D fish/N \n",
    "\n",
    "the/D fish/N is/VV in/P the/D fish/N can/N \n",
    "\n",
    "workers/N can/VV the/D fish/N\n",
    "```\n",
    "\n",
    "Reminder: The MLE estimates can be obtained by \n",
    "$$P(s_i|s_j)=\\frac{C(s_i,s_j)}{C(s_j)} \\qquad \\text{and} \\qquad P(w_k|s_i)=\\frac{C(w_k,s_i)}{C(s_i)}\\quad,$$\n",
    "where $C$ is the count function. \n",
    "\n",
    "The following initial model shows the transition probability and the transition probability for one word.\n",
    "<img src=\"1hmm_states_with_init_to_show_stud.png\" alt=\"init\" width=\"50%\"/>\n",
    "\n",
    "### b) Tag the following texts, using the HMM from a) and provide the probabilities of the sequences given the observation. \n",
    "\n",
    "```\n",
    "a cat can \n",
    "\n",
    "a cat can can\n",
    "\n",
    "```\n",
    "```\n",
    "------\n",
    "</S>\n",
    "\n",
    "P           P        P        P \n",
    "\n",
    "VV          VV       VV       VV\n",
    "\n",
    "VA          VA       VA       VA\n",
    "\n",
    "N           N        N        N\n",
    " \n",
    "D           D        D        D\n",
    "\n",
    "<S>         a        cat      run\n",
    "------\n",
    "```\n",
    "\n",
    "The following sketch from the lecture shows on how to compute the probabilities of the sequence.\n",
    "<img src=\"viterbi_li_pr.png\" alt=\"viterbi\" width=\"90%\"/>\n",
    "\n",
    "### c) What is the probability of the following sequence?  \n",
    "\n",
    "``` \n",
    "the workers can can the food in a can \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a91486",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Problem 5.2 CRF ++ </span>\n",
    "Download and install **CRF++** from http://taku910.github.io/crfpp/  (tested with version 0.58; Linux users might need to install g++).\n",
    "\n",
    "Download the **PC5-data.tar.gz** file from Moodle and unpack it. For evaluation, you need to have access to Perl (Windows users can use Babun, http://babun.github.io/).\n",
    "\n",
    "### a) Let's have a look at the data. What do the columns mean? What is the task? What makes sense to check for evaluation, Token-level accuracy vs. chunk-level P/R/FB1? The description can be found at https://www.clips.uantwerpen.be/conll2000/chunking/\n",
    "\n",
    "```Confidence      NN      B-NP\n",
    "in      IN      B-PP\n",
    "the     DT      B-NP\n",
    "pound   NN      I-NP\n",
    "is      VBZ     B-VP\n",
    "widely  RB      I-VP\n",
    "expected        VBN     I-VP\n",
    "to      TO      I-VP\n",
    "take    VB      I-VP\n",
    "another DT      B-NP\n",
    "sharp   JJ      I-NP\n",
    "dive    NN      I-NP\n",
    "if      IN      B-SBAR\n",
    "trade   NN      B-NP\n",
    "figures NNS     I-NP\n",
    "for     IN      B-PP\n",
    "September       NNP     B-NP\n",
    ",       ,       O\n",
    "due     JJ      B-ADJP\n",
    "for     IN      B-PP\n",
    "release NN      B-NP\n",
    "tomorrow        NN      B-NP\n",
    ",       ,       O\n",
    "fail    VB      B-VP\n",
    "to      TO      I-VP\n",
    "show    VB      I-VP\n",
    "a       DT      B-NP\n",
    "substantial     JJ      I-NP\n",
    "improvement     NN      I-NP\n",
    "from    IN      B-PP\n",
    "July    NNP     B-NP\n",
    "and     CC      I-NP\n",
    "August  NNP     I-NP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aca07a",
   "metadata": {},
   "source": [
    "### b) Let’s train a CRF on the small training data that only is conditioned on the POS tag at the current position and on the neighbor (-1, +1) output tags (bigram option).\n",
    "\n",
    "```\n",
    "------ pc5.template ------\n",
    "U11:%x[0,1]\n",
    "B\n",
    "```\n",
    "\n",
    "command: \n",
    "```$ crf_learn -m 200 pc5.template train.small.data pc5b.small.model```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1205336",
   "metadata": {},
   "source": [
    "### c) Now, let us apply it to the small validation data. Look at the output and evaluate it using the provided perl script. \n",
    " \n",
    "```$ crf_test -m pc5b.small.model vali.small.data  > vali.pc5b.output ```\n",
    "\n",
    "\n",
    "```$ perl conlleval.pl < vali.pc5b.output ```\n",
    "\n",
    "\n",
    "The output should look like the following\n",
    "\n",
    "\n",
    "```\n",
    "accuracy:  89.76%; precision:  83.21%; recall:  81.32%; FB1:  82.26\n",
    "             ADJP: precision:  53.33%; recall:  21.62%; FB1:  30.77  30\n",
    "             ADVP: precision:  62.60%; recall:  60.74%; FB1:  61.65  131\n",
    "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "               NP: precision:  82.67%; recall:  80.37%; FB1:  81.50  2031\n",
    "               PP: precision:  83.91%; recall:  96.80%; FB1:  89.89  901\n",
    "              PRT: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "             SBAR: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "               VP: precision:  88.22%; recall:  88.22%; FB1:  88.22  815\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ce26c",
   "metadata": {},
   "source": [
    "### d) Let’s extend the model to use also the preceding (-1) and following (1) POS tag. What happens to the error rates while training? What happens in the evaluation?\n",
    "\n",
    "```\n",
    "------ pc5.template: ------ \n",
    "U11:%x[-1,1] \n",
    "U21:%x[0,1] \n",
    "U31:%x[1,1] \n",
    "B \n",
    "```\n",
    "\n",
    "commands:\n",
    " \n",
    "```$ crf_learn -m 200 pc5.template  train.small.data pc5d.small.model```\n",
    "\n",
    "```$ crf_test -m pc5d.small.model vali.small.data | perl conlleval.pl```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876de18",
   "metadata": {},
   "source": [
    "### e)  Let’s extend it for POS in positions -2 and 2. Explain error rates and performance measures. \n",
    "```\n",
    "------ pc5.template: ------ \n",
    "U11:%x[-2,1] \n",
    "U21:%x[-1,1] \n",
    "U31:%x[0,1] \n",
    "U41:%x[1,1] \n",
    "U51:%x[2,1] \n",
    "B \n",
    "```\n",
    "commands:\n",
    "\n",
    "```$ crf_learn -m 200 pc5.template  train.small.data pc5e.small.model```\n",
    "\n",
    "```$ crf_test -m pc5e.small.model vali.small.data | perl conlleval.pl```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8f1e5",
   "metadata": {},
   "source": [
    "### f)  Add POS bigram features [-2,-1] and [1,2]. Error rates? Performance measures? \n",
    "\n",
    "``` \n",
    "------ pc5.template: ------ \n",
    "U11:%x[-2,1] \n",
    "U21:%x[-1,1] \n",
    "U31:%x[0,1] \n",
    "U41:%x[1,1] \n",
    "U51:%x[2,1] \n",
    "U62:%x[-2,1]/%x[-1,1] \n",
    "U72:%x[1,1]/%x[2,1] \n",
    "B \n",
    "```\n",
    "\n",
    "commands:\n",
    "\n",
    "```$ crf_learn -m 200 pc5.template  train.small.data pc5f.small.model ```\n",
    "\n",
    "```$ crf_test -m pc5f.small.model vali.small.data | perl conlleval.pl ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119e907",
   "metadata": {},
   "source": [
    "### g) Add the current word to the features from \\textit{d}). Does it help?\n",
    "\n",
    "```  \n",
    "------ pc5.template: ------ \n",
    "U00:\\%x[0,0] \n",
    "U11:\\%x[-1,1] \n",
    "U21:\\%x[0,1] \n",
    "U31:\\%x[1,1] \n",
    "B \n",
    "```\n",
    "\n",
    "commands: \n",
    "\n",
    "```$ crf_learn -m 200 pc5.template  train.small.data pc5g.small.model ```\n",
    "\n",
    "```$ crf_test -m pc5g.small.model vali.small.data | perl conlleval.pl ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be749a41",
   "metadata": {},
   "source": [
    "### h) Experiment: Who can build the best model for the small data, and how well does it perform on the yet unseen test data (```test.small.data```)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53c1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f24d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "482e7c18",
   "metadata": {},
   "source": [
    "# Good luck with your assignment :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
