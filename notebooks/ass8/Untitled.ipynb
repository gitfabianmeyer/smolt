{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b944a3-92ac-42bd-80cc-336229cef188",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## add interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb989f50-7a46-4ecf-bb3b-eb6d3338b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae299dd6-c47b-4580-be55-74e10ae7295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"e\": \"Skills and Hobbies\",\n",
    "              \"h\": \"Miscellaneous: Government Documents\",\n",
    "              \"k\":  \"Fiction: General\",\n",
    "              \"n\": \"Fiction: Adventure\",\n",
    "              \"p\": \"Fiction: Romance\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64d77ec-d70e-470f-8a89-aa3796e69c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    corpus=[]\n",
    "    labels = []\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file)\n",
    "        with open(filepath, 'r') as i:\n",
    "            # read content and remove newline char\n",
    "            s = i.read().replace(\"\\n\",\"\")\n",
    "            corpus.append(s)\n",
    "            labels.append(file[1])\n",
    "    print(f\"length corpus: {len(corpus)}\")\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6b91f-c437-43cf-a1f6-a253a081b5f2",
   "metadata": {},
   "source": [
    "### a) Perform SVD with k = 2 on the training data and plot the first two dimensions of the latent document matrix U. Briefly describe what you observe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f0f7284-6870-469e-994b-c1393e242f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 95\n",
      "Explained variance ratio: [0.08325744 0.21933445]\n",
      "Singular values: [1849.29221369  468.82074881]\n",
      "Topic Doc 1: Skills and Hobbies\n",
      "Topic Doc 2: Skills and Hobbies\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = read(\"./HW-10-data/training\")\n",
    "vectorizer = CountVectorizer(lowercase =True, stop_words=None, max_df=1.0, min_df=1)\n",
    "svd = TruncatedSVD(n_components=2,n_iter=50, random_state=42)\n",
    "normalizer = Normalizer(copy = False)\n",
    "\n",
    "lsa = make_pipeline(vectorizer,svd, normalizer)\n",
    "X_SVD = lsa.fit_transform(X_train)\n",
    "print(f\"Explained variance ratio: {svd.explained_variance_ratio_}\")\n",
    "print(f\"Singular values: {svd.singular_values_}\")\n",
    "X_SVD.shape\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_SVD[0], 'og', alpha=0.5, label='Train 1')\n",
    "ax.plot(X_SVD[1], 'ob', alpha=0.5, label='Train 2')\n",
    "ax.legend()\n",
    "print(f\"Topic Doc 1: {label_dict[y_train[0]]}\")\n",
    "print(f\"Topic Doc 2: {label_dict[y_train[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46769b-2be7-43c4-bb41-f325a6ee54b5",
   "metadata": {},
   "source": [
    "The observable plot for the first two documents show a strong similarity for the SVD plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456832fd-cb56-4cc2-befb-3e890a256de2",
   "metadata": {},
   "source": [
    "### Load the test data, transform the documents into the latent vector space of the training model from a) and plot the resulting data into the same figure as a) but make sure they are distinguishable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d1a115-63ba-493b-b37c-f8a76ea03a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 50\n",
      "Topic Train 1: Skills and Hobbies\n",
      "Topic Train 2: Skills and Hobbies\n",
      "Topic Test 1: Skills and Hobbies\n",
      "Topic Test 2: Skills and Hobbies\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = read(\"./HW-10-data/test\")\n",
    "X_SVD_test = lsa.transform(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_SVD[0], 'og', alpha=0.5, label='Train 1')\n",
    "ax.plot(X_SVD[1], 'ob', alpha=0.5, label='Train 2')\n",
    "ax.plot(X_SVD_test[0], 'oy', alpha=0.5, label=\"Test 1\")\n",
    "ax.plot(X_SVD_test[1], 'or', alpha=0.5, label=\"Test 1\")\n",
    "ax.legend()\n",
    "\n",
    "print(f\"Topic Train 1: {label_dict[y_train[0]]}\")\n",
    "print(f\"Topic Train 2: {label_dict[y_train[1]]}\")\n",
    "print(f\"Topic Test 1: {label_dict[y_test[0]]}\")\n",
    "print(f\"Topic Test 2: {label_dict[y_test[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9400e85-1986-4a26-a688-c528b726cc23",
   "metadata": {},
   "source": [
    "Additional to the two plots of the first part, which are very similar, we observe a slightly difference with respect to the two dimension. This can be interpreted as difference of the documents, even though they rely to the same label as the train documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf42b95-3bfb-4d8b-bcd7-32c1c080a602",
   "metadata": {},
   "source": [
    "### Remove stopwords using a stopword list (this list can be found in the file stopwords.txt). Run again SVD and plot the training and test documents. Briefly describe differences to the plot in 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51e5c95-08ce-4893-a140-f4de0ca27f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords():\n",
    "    p = \"./HW-10-data/stopwords.txt\"\n",
    "    with open(p) as file:\n",
    "        return file.read().split(\"\\n\")\n",
    "stopwords = read_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b98b690b-23d9-48e5-821c-a309b7e3bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmeyer\\Anaconda3\\envs\\smolt\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Doc 1: Skills and Hobbies\n",
      "Topic Doc 2: Skills and Hobbies\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = read(\"./HW-10-data/training\")\n",
    "vectorizer2 = CountVectorizer(lowercase =True, stop_words=stopwords, max_df=1.0, min_df=1)\n",
    "svd2 = TruncatedSVD(n_components=2,n_iter=50, random_state=42)\n",
    "normalizer2 = Normalizer(copy = False)\n",
    "lsa2 = make_pipeline(vectorizer2,svd2, normalizer2)\n",
    "X_SVD2 = lsa2.fit_transform(X_train)\n",
    "X_SVD2.shape\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_SVD2[0], 'og', alpha=0.5, label='Train 1')\n",
    "ax.plot(X_SVD2[1], 'ob', alpha=0.5, label='Train 2')\n",
    "ax.legend()\n",
    "print(f\"Topic Doc 1: {label_dict[y_train[0]]}\")\n",
    "print(f\"Topic Doc 2: {label_dict[y_train[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885fc52-3a5e-4059-bb95-14c8fc4b8ef4",
   "metadata": {},
   "source": [
    "Removing stopwords leads to a slightly greater difference of the documents. This is not surprising, as we remove many similar words from both documents. The remaining words are \"rarer\" in general w.r.t. the language and thus less likely to occur in both documents, leading to greater differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8ec655e-9f21-4b5c-9133-4e6445730a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 50\n",
      "Topic Train 1: Skills and Hobbies\n",
      "Topic Train 2: Skills and Hobbies\n",
      "Topic Test 1: Skills and Hobbies\n",
      "Topic Test 2: Skills and Hobbies\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZsElEQVR4nO3df3DV9Z3v8eeb/DihJYRI4sJwOAVmo4h6DDRV0DurjHrrjyputu3CrVPZesvoXkTvNmttabuMW2d0m7Ud5nrrsl1r7d2tujbaWPEyt62MziLVOLopoNQs4uFQhJAeD+liQkLe949zhBCCnHC+OUnO9/WYyZzv9/P95HzeH9BXvvl+v+eDuTsiIlL8Jo11ASIiUhgKfBGRkFDgi4iEhAJfRCQkFPgiIiFROtYFnEpNTY3PmTNnrMsQEZlQXnvttYPuXjvcsXEb+HPmzKGtrW2syxARmVDM7N1THdMlHRGRkFDgi4iERCCBb2aPmNkBM9t2iuNmZuvNrMPM2s1sURDjiohI7oK6hv8o8L+Ax05x/FqgLvt1CfD97KuISE76+vpIJpP09PSMdSnjQkVFBdFolLKyspy/J5DAd/cXzWzOR3RZBjzmmYV7tprZNDOb6e77ghhfRIpfMpmksrKSOXPmYGZjXc6Ycne6urpIJpPMnTs35+8r1FM6s4A9g/aT2bYTAt/MVgGrAGKx2BkN1N3dzsGDLfT2JohEYtTUNFJZGT+zqkVk3Ojp6VHYZ5kZ06dPp7Ozc0TfN64ey3T3DcAGgIaGhhEv49nd3c5v3l7LrkMH6OrpZXrFdualXuPCuvsU+iJFQGF/3Jn8WRTqKZ29wOxB+9FsW6C27/4+rx/ooLsPpkaq6O6D1w90sH3394MeSkRkwilU4LcCX8w+rbMYSI/G9ft3urZS8+4kFv/zfv7L3+1k8T/vp+bdSbzTtTXooUQkZLq6uqivr6e+vp4ZM2Ywa9asY/tHjhz5yO9ta2tjzZo1Ixpv7dq1zJ49mylTpuRT9gkCuaRjZj8BrgBqzCwJ/A1QBuDuDwMbgeuADuAw8BdBjDtU/47/5NJnfk9vZYT/rI0Q6e6j4af72XLTWZnqRCQ02t9rp+WtFhLpBLGqGI3zG4nPOPNLu9OnT+eNN94AYN26dUyZMoWmpqZjx/v7+yktHT5SGxoaaGhoGNF4N9xwA6tXr6auru6Max4qqKd0VpzmuAP/I4ixPsrcV6ZyuDxFumcqPanJVEz+gKryg8x9ZSr85WiPLiLjRft77TS/3Ex1RTXRqVFSH6RofrmZpiVNeYX+UCtXrqSiooLXX3+dyy67jOXLl3PnnXfS09PD5MmT+eEPf8i5557L5s2baW5u5uc//znr1q0jkUiwa9cuEokEd91117Bn/4sXLw6szg+Nq5u2+Zr13ifYnJhFdOa7TPn4If5weApv77uUK/qLapoichotb7VQXVFN9eRqgGOvLW+1BBr4kHlcdMuWLZSUlHDo0CFeeuklSktL+cUvfsHXv/51fvrTn570PW+99RYvvPAC3d3dnHvuudx+++0jep7+TBVVEu7uuZAZtpe9XdX07O+horSCGVbG7p5Z5P6kqohMdIl0gujU6AltVRVVJNKJwMf63Oc+R0lJCQDpdJpbbrmFt99+GzOjr69v2O+5/vrriUQiRCIRzj77bPbv3080Gh22b5CKai2dX01rZEZJL/MjVcyffg7zI1XMKOnlV9Max7o0ESmgWFWMdE/6hLZ0T5pY1Zl9vuejfPzjHz+2/c1vfpOlS5eybds2nn322VN+KjgSiRzbLikpob+/P/C6hlNUgV9SH2fTBU18MLmaqkNJPphczaYLmiip1zP4ImHSOL+RVE+K1AcpBnyA1AcpUj0pGueP7slfOp1m1qxZADz66KOjOtaZKKrAb2yEHaVxnrloHU/f8AjPXLSOHaVxGnWCLxIq8RlxmpY0UT25muShJNWTqwO/YTucu+++m6997WssXLgw77P2u+++m2g0yuHDh4lGo6xbty7v+izzAM3409DQ4GfyD6C0t0NLCyQSEItlfgjEdYIvMuG9+eabnHfeeWNdxrgy3J+Jmb3m7sM+A1pUN20hE+4KeBGRkxXVJR0RETk1Bb6ISEgo8EVEQkKBLyISEgp8EZGQUOCLiOSgkMsjHz58mOuvv5758+dz/vnnc8899+RbPlCEj2WKiEDwn8kp9PLITU1NLF26lCNHjnDllVfy/PPPc+21155x/aAzfBEpQu3t0NwMqRREo5nX5uZMe5BWrlzJbbfdxiWXXMLdd9/NK6+8wpIlS1i4cCGXXnopO3fuBGDz5s185jOfATI/LL70pS9xxRVXMG/ePNavX3/S+37sYx9j6dKlAJSXl7No0SKSyWTe9eoMX0SKTksLVFdnvuD4a0tL8B/MHO3lkd9//32effZZ7rzzzrxrVeCLSNFJJDJn9oNVVWXagzaayyP39/ezYsUK1qxZw7x58/KuVZd0RKToxGKQPnF1ZNLpTHvQRnN55FWrVlFXV8ddd90VSK0KfBEpOo2Nmev2qRQMDBzfHu2Vc4NcHvkb3/gG6XSa733ve/kXlqXAF5GiE49DU1Pm2n0ymXltahr9hRWDWh45mUxy3333sWPHDhYtWkR9fT0/+MEP8q6v6JZHFpHipOWRTzbS5ZF1hi8iEhKBBL6ZXWNmO82sw8xO+kiYmcXM7AUze93M2s3suiDGFRGR3OUd+GZWAjwEXAssAFaY2YIh3b4BPOnuC4HlwP/Od1wRERmZIM7wLwY63H2Xux8BHgeWDenjwNTsdhXwuwDGFRGREQgi8GcBewbtJ7Ntg60DbjazJLARuGO4NzKzVWbWZmZtnZ2dAZQmIiIfKtRN2xXAo+4eBa4DfmxmJ43t7hvcvcHdG2prawtUmohIOAQR+HuB2YP2o9m2wW4FngRw95eBCqAmgLFFRAoin+WRIbOA2pYtW4Y99tZbb7FkyRIikQjNzc1Bl35MEGvpvArUmdlcMkG/HPhvQ/okgCuBR83sPDKBr2s2IjJqurvbOXiwhd7eBJFIjJqaRiorz/yTV6dbHvl0Nm/ezJQpU7j00ktPOnbWWWexfv16nnnmmTOuLxd5n+G7ez+wGtgEvEnmaZztZnavmd2Y7fYV4Mtm9u/AT4CVPl4/8SUiE153dzvJZDN9fSnKy6P09aVIJpvp7g52feTXXnuNyy+/nE9+8pN8+tOfZt++fQCsX7+eBQsWEI/HWb58Obt37+bhhx/mu9/9LvX19bz00ksnvM/ZZ5/Npz71qVOumBmUQFbLdPeNZG7GDm771qDtHcBlQYwlInI6Bw+2UFJSTVlZZl3kD18PHmzJ6yx/MHfnjjvu4Gc/+xm1tbU88cQTrF27lkceeYT777+fd955h0gkwvvvv8+0adO47bbbRvxbQdC0PLKIFJ3e3gTl5ScuN1xaWkVvb3DrI/f29rJt2zauvvpqAI4ePcrMmTMBiMfjfOELX+Cmm27ipptuCmzMfCnwRaToRCIx+vpSx87sAfr700Qiwa2P7O6cf/75vPzyyycde+6553jxxRd59tlnue+++/jNb34T2Lj50Fo6IlJ0amoaOXo0RV9fCvcB+vpSHD2aoqYmuPWRI5EInZ2dxwK/r6+P7du3MzAwwJ49e1i6dCkPPPAA6XSaP/zhD1RWVtLd3R3Y+GdCgS8iRaeyMk402kRZWTVHjiQpK6smGm0K7Po9wKRJk3jqqaf46le/ykUXXUR9fT1btmzh6NGj3HzzzVx44YUsXLiQNWvWMG3aNG644QaefvrpYW/avvfee0SjUR588EG+/e1vE41GOXToUGC1fkjLI4vIhKDlkU+m5ZFFRGRYCnwRkZBQ4IuIhIQCX0QkJBT4IiIhocAXEQkJBb6ISA60PLKIyHjV3g4tLZBIQCwGjY0Q1/LIIiLFpb0dmpshlYJoNPPa3JxpD1Aol0cWERlXWlqgujrzBcdfW1ryOssfTMsji4iMB4lE5sx+sKqqTHtAtDyyiMh4EItlLuNUH18emXQ60x4QLY8sIjIeNDZmAj+VgoGB49uNWh5ZRKS4xOPQ1JQ5w08mM69NTYFdvwctjxwoLY8sIoNpeeSTaXlkEREZlgJfRCQkAgl8M7vGzHaaWYeZ3XOKPp83sx1mtt3M/iWIcUUkXMbrJeixcCZ/Fnk/lmlmJcBDwNVAEnjVzFrdfcegPnXA14DL3D1lZmfnO66IhEtFRQVdXV1Mnz4dMxvrcsaUu9PV1UVFRcWIvi+I5/AvBjrcfReAmT0OLAN2DOrzZeAhd09liz0QwLgiEiLRaJRkMklnZ+dYlzIuVFRUEB364bLTCCLwZwF7Bu0ngUuG9DkHwMz+DSgB1rn7/x36Rma2ClgFEAvwAxIiMvGVlZUxd+7csS5jQivUTdtSoA64AlgB/KOZTRvayd03uHuDuzfU1tYWqDQRkXAIIvD3ArMH7UezbYMlgVZ373P3d4DfkvkBICIiBRJE4L8K1JnZXDMrB5YDrUP6PEPm7B4zqyFziWdXAGOLiEiO8g58d+8HVgObgDeBJ919u5nda2Y3ZrttArrMbAfwAvDX7t6V79giIpI7La0gIlJEtLSCiIgo8EVEwkKBLyISEgp8EZGQUOCLiISEAl9EJCQU+CIiIaHAFxEJCQW+iEhIKPBFREJCgS8iEhIKfBGRkFDgi4iEhAJfRCQkFPgiIiGhwBcRCQkFvohISCjwRURCQoEvIhISCnwRkZBQ4IuIhIQCX0QkJAIJfDO7xsx2mlmHmd3zEf3+zMzczBqCGFdERHKXd+CbWQnwEHAtsABYYWYLhulXCdwJ/DrfMUVEZOSCOMO/GOhw913ufgR4HFg2TL+/BR4AegIYU0RERiiIwJ8F7Bm0n8y2HWNmi4DZ7v7cR72Rma0yszYza+vs7AygNBER+dCo37Q1s0nAg8BXTtfX3Te4e4O7N9TW1o52aSIioRJE4O8FZg/aj2bbPlQJXABsNrPdwGKgVTduRUQKK4jAfxWoM7O5ZlYOLAdaPzzo7ml3r3H3Oe4+B9gK3OjubQGMLSIiOco78N29H1gNbALeBJ509+1mdq+Z3Zjv+4uISDBKg3gTd98IbBzS9q1T9L0iiDFFRGRk9ElbEZGQUOCLiISEAl9EJCQU+CIiIaHAFxEJCQW+iEhIKPBFREJCgS8iEhIKfBGRkFDgi4iEhAJfRCQkAllLR0REAtDeDi0tkEhALAaNjRCPB/b2OsMXERkP2tuhuRlSKYhGM6/NzZn2gCjwRUTGg5YWqK7OfE2adHy7pSWwIRT4IiLjQSIBVVUntlVVZdoDosAXERkPYjFIp09sS6cz7QFR4IuIjAeNjZnr9qkUDAwc325sDGwIBb6IyHgQj0NTU+a6fTKZeW1qCvQpHT2WKSIyXsTjgQb8UDrDFxEJCQW+iEhIBBL4ZnaNme00sw4zu2eY439lZjvMrN3MfmlmnwhiXBERyV3egW9mJcBDwLXAAmCFmS0Y0u11oMHd48BTwN/lO66IiIxMEGf4FwMd7r7L3Y8AjwPLBndw9xfc/XB2dysQDWBcEREZgSACfxawZ9B+Mtt2KrcCzw93wMxWmVmbmbV1dnYGUJqIiHyooDdtzexmoAH4znDH3X2Duze4e0NtbW0hSxMRKXpBPIe/F5g9aD+abTuBmV0FrAUud/feAMYVEZERCOIM/1Wgzszmmlk5sBxoHdzBzBYC/wDc6O4HAhhTRERGKO/Ad/d+YDWwCXgTeNLdt5vZvWZ2Y7bbd4ApwL+a2Rtm1nqKtxMRkVESyNIK7r4R2Dik7VuDtq8KYhwRETlz+qStiEhIKPBFREJCgS8iEhIKfBGRkFDgi4iEhAJfRCQkFPgiIiGhwBcRCQkFvohISCjwRURCQoEvIhISCnwRkZBQ4IuIhIQCX0QkJBT4IiIhocAXEQkJBb6ISEgo8EVEQkKBLyISEgp8EZGQUOCLiISEAl9EJCQCCXwzu8bMdppZh5ndM8zxiJk9kT3+azObE8S4IiKSu7wD38xKgIeAa4EFwAozWzCk261Ayt3/GPgu8EC+44qIyMgEcYZ/MdDh7rvc/QjwOLBsSJ9lwI+y208BV5qZBTC2iIjkKIjAnwXsGbSfzLYN28fd+4E0MH3oG5nZKjNrM7O2zs7OAEoTEZEPjaubtu6+wd0b3L2htrZ2rMsRESkqQQT+XmD2oP1otm3YPmZWClQBXQGMLSIiOQoi8F8F6sxsrpmVA8uB1iF9WoFbstufBX7l7h7A2CIikqPSfN/A3fvNbDWwCSgBHnH37WZ2L9Dm7q3APwE/NrMO4PdkfiiIiEgB5R34AO6+Edg4pO1bg7Z7gM8FMZaIiJyZcXXTVkRERo8CX0QkJBT4IiIhocAXEQkJBb6ISEgo8EVEQkKBLyISEgp8EZGQUOCLiISEAl9EJCQU+CIiIaHAFxEJCQW+iEhIKPBFREJCgS8iEhIKfBGRkFDgi4iEhAJfRCQkFPgiIiGhwBcRCQkFvohISJSOdQEiIpLR3d3OwYMt9PYmiERi1NQ0UlkZD+z98zrDN7OzzOz/mdnb2dfqYfrUm9nLZrbdzNrN7M/zGVNEpBh1d7eTTDbT15eivDxKX1+KZLKZ7u72wMbI95LOPcAv3b0O+GV2f6jDwBfd/XzgGuB7ZjYtz3FFRIrKwYMtlJRUU1ZWjdkkysqqKSmp5uDBlsDGyDfwlwE/ym7/CLhpaAd3/627v53d/h1wAKjNc1wRkaLS25ugtLTqhLbS0ip6exOBjZHvNfw/cvd92e33gD/6qM5mdjFQDvzHKY6vAlYBxGKxPEsTEZk4IpEY+9Jv89v395LuSVNVUcU502Yxs6ousDFOG/hm9gtgxjCH1g7ecXc3M/+I95kJ/Bi4xd0Hhuvj7huADQANDQ2nfC8RkWKTsgvYvv8xbNJUpkam0t/3Ptv3J6iY9qfMDWiM0wa+u191qmNmtt/MZrr7vmygHzhFv6nAc8Bad996xtWKiBSp1t3bOOqLmVf2OypI01M2jV09C9i7exuL5nw2kDHyvaTTCtwC3J99/dnQDmZWDjwNPObuT+U5nohIUUqkE0Sn/jHvcs6xNosMkEgHdw0/35u29wNXm9nbwFXZfcyswcx+kO3zeeBPgJVm9kb2qz7PcUVEikqsKka6J31CW7onTawquPuZeQW+u3e5+5XuXufuV7n777Ptbe7+37Pb/8fdy9y9ftDXGwHULiJSNBrnN5LqSZH6IMWAD5D6IEWqJ0Xj/MbAxtDSCiIi40B8RpymJU1UT64meShJ9eRqmpY0EZ8R3CdttbSCiMg4EZ8RDzTgh9IZvohISCjwRURCQoEvIhISCnwRkZBQ4IuIhISe0hERGSfa26GlBRIJiMWgsRHiAT60ozN8EZFxoL0dmpshlYJoNPPa3JxpD4oCX0RkHGhpgerqzNekSce3W4L7908U+CIi40EiAVUn/vsnVFVl2oOiwBcRGQdiMUifuHYa6XSmPSgKfBGRcaCxMXPdPpWCgYHj243BrZ2mwBcRGQ/icWhqyly3TyYzr01NwT6lo8cyRUTGiXg82IAfSmf4IiIhocAXEQkJBb6ISEgo8EVEQkKBLyISEubuY13DsMysE3g3j7eoAQ4GVM5EEbY5h22+oDmHRT5z/oS71w53YNwGfr7MrM3dG8a6jkIK25zDNl/QnMNitOasSzoiIiGhwBcRCYliDvwNY13AGAjbnMM2X9Ccw2JU5ly01/BFRORExXyGLyIigyjwRURCYkIHvpldY2Y7zazDzO4Z5njEzJ7IHv+1mc0ZgzIDlcOc/8rMdphZu5n90sw+MRZ1Bul0cx7U78/MzM1swj/Cl8uczezz2b/r7Wb2L4WuMWg5/LcdM7MXzOz17H/f141FnUExs0fM7ICZbTvFcTOz9dk/j3YzW5T3oO4+Ib+AEuA/gHlAOfDvwIIhff4SeDi7vRx4YqzrLsCclwIfy27fHoY5Z/tVAi8CW4GGsa67AH/PdcDrQHV2/+yxrrsAc94A3J7dXgDsHuu685zznwCLgG2nOH4d8DxgwGLg1/mOOZHP8C8GOtx9l7sfAR4Hlg3pswz4UXb7KeBKM7MC1hi0087Z3V9w98PZ3a1AtMA1Bi2Xv2eAvwUeAHoKWdwoyWXOXwYecvcUgLsfKHCNQctlzg5MzW5XAb8rYH2Bc/cXgd9/RJdlwGOesRWYZmYz8xlzIgf+LGDPoP1ktm3YPu7eD6SB6QWpbnTkMufBbiVzhjCRnXbO2V91Z7v7c4UsbBTl8vd8DnCOmf2bmW01s2sKVt3oyGXO64CbzSwJbATuKExpY2ak/7+flv7FqyJlZjcDDcDlY13LaDKzScCDwMoxLqXQSslc1rmCzG9xL5rZhe7+/lgWNcpWAI+6+9+b2RLgx2Z2gbsPjHVhE8VEPsPfC8wetB/Ntg3bx8xKyfwa2FWQ6kZHLnPGzK4C1gI3untvgWobLaebcyVwAbDZzHaTudbZOsFv3Oby95wEWt29z93fAX5L5gfARJXLnG8FngRw95eBCjKLjBWrnP5/H4mJHPivAnVmNtfMysnclG0d0qcVuCW7/VngV569GzJBnXbOZrYQ+AcyYT/Rr+vCaebs7ml3r3H3Oe4+h8x9ixvdvW1syg1ELv9tP0Pm7B4zqyFziWdXAWsMWi5zTgBXApjZeWQCv7OgVRZWK/DF7NM6i4G0u+/L5w0n7CUdd+83s9XAJjJ3+B9x9+1mdi/Q5u6twD+R+bWvg8zNkeVjV3H+cpzzd4ApwL9m708n3P3GMSs6TznOuajkOOdNwH81sx3AUeCv3X3C/vaa45y/Avyjmf1PMjdwV07kEzgz+wmZH9o12fsSfwOUAbj7w2TuU1wHdACHgb/Ie8wJ/OclIiIjMJEv6YiIyAgo8EVEQkKBLyISEgp8EZGQUOCLiISEAl9EJCQU+CIiIfH/AQST1J14Wzo8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = read(\"./HW-10-data/test\")\n",
    "\n",
    "X_SVD_test2 = lsa2.transform(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_SVD2[0], 'og', alpha=0.5, label='Train 1')\n",
    "ax.plot(X_SVD2[1], 'ob', alpha=0.5, label='Train 2')\n",
    "ax.plot(X_SVD_test2[0], 'oy', alpha=0.5, label=\"Test 1\")\n",
    "ax.plot(X_SVD_test2[1], 'or', alpha=0.5, label=\"Test 1\")\n",
    "ax.legend()\n",
    "\n",
    "print(f\"Topic Train 1: {label_dict[y_train[0]]}\")\n",
    "print(f\"Topic Train 2: {label_dict[y_train[1]]}\")\n",
    "print(f\"Topic Test 1: {label_dict[y_test[0]]}\")\n",
    "print(f\"Topic Test 2: {label_dict[y_test[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbc33f-67d6-4f86-8122-d9ddd30e8479",
   "metadata": {},
   "source": [
    "Similar to the observations in the last subtask, the test docs diverge even more, for the same reasons as stated before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d820dcf-b790-4e84-a5a7-d6727673f84b",
   "metadata": {},
   "source": [
    "### 2) LDA  \n",
    "As I problems running GibbsLDA on my system, I used scikit learns implementation, which differs slightly as it uses variational interference instead of Gibbs sampling. This might lead to slightly different results, but in general should yield similar reasonable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa06532f-3c6a-4325-8466-2715aafa858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_likely_words(vocab, lda_model, n=100):\n",
    "    res =  {}\n",
    "    for i, topic in enumerate(lda_model.components_):\n",
    "        topic_dict = {}\n",
    "        # get position of n highest values\n",
    "        positions = topic.argsort()[-n:][::-1]\n",
    "        # get words for n highest positions\n",
    "        words = [vocab[i] for i in positions]\n",
    "        res[i] = words\n",
    "    return res\n",
    "        # use for evaluation\n",
    "        #for e, position in enumerate(positions):\n",
    "        #    # create in json format\n",
    "        #    topic_dict[e] = {words[e]: round(topic[position], 2)}\n",
    "            #print(f\"{e}: {words[e]}: {topic[position]}\")\n",
    "        #res[i] = topic_dict\n",
    "    #return res\n",
    "# TODO put results into dicts and merge them to get evolution of topics\n",
    "\n",
    "def get_compact(history):\n",
    "    res = {}\n",
    "    # for every run\n",
    "    for r, run in enumerate(history.keys()):\n",
    "        \n",
    "        # take each topic\n",
    "        for topic in history[run].keys():\n",
    "            try:\n",
    "                res[topic].append(history[run][topic])\n",
    "            except KeyError:\n",
    "                res[topic] = [history[run][topic]]\n",
    "    return res\n",
    "def calc_overlap(compact_history):\n",
    "    for topic in compact_history.keys():\n",
    "        print(f\"Topic {topic}:\")\n",
    "        for i in range(len(compact_history[topic])-1):\n",
    "            over = overlap(compact_history[topic][i], compact_history[topic][i+1])\n",
    "            print(f\"Overlap run {i} to run {i+1}: {over} ({over /len(compact_history[topic][i])} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973dde12-dd7d-4a34-8ca3-62911a0fcbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 95\n",
      "{0: ['the', 'and', 'of', 'to', 'in', 'he', 'was', 'it', 'that', 'for', 'his', 'with', 'on', 'had', 'is', 'you', 'be', 'as', 'at', 'she', 'her', 'this', 'but', 'him', 'they', 'from', 'or', 'not', 'by', 'have', 'would', 'one', 'all', 'were', 'are', 'there', 'out', 'an', 'said', 'when', 'we', 'their', 'which', 'no', 'up', 'if', 'what', 'so', 'them', 'could', 'about', 'been', 'into', 'me', 'like', 'my', 'can', 'will', 'time', 'more', 'its', 'now', 'then', 'only', 'do', 'who', 'other', 'over', 'two', 'any', 'man', 'down', 'back', 'your', 'state', 'has', 'than', 'did', 'made', 'such', 'long', 'before', 'just', 'new', 'some', 'our', 'these', 'way', 'first', 'little', 'where', 'through', 'get', 'must', 'here', 'how', 'after', 'even', 'well', 'may']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "X_train, y_train = read(\"./HW-10-data/training\")\n",
    "stopwords = read_stopwords()\n",
    "vectorizer3 = CountVectorizer(lowercase =True, stop_words=None, max_df=1.0, min_df=1)\n",
    "X = vectorizer3.fit_transform(X_train)\n",
    "lda = LatentDirichletAllocation(n_components=1, random_state=42, n_jobs=-1)\n",
    "lda.fit(X)\n",
    "vocab = {v: k for k, v in vectorizer3.vocabulary_.items()}\n",
    "print(get_n_most_likely_words(vocab, lda, n=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263638a-2d2d-421e-9f12-106699a711d6",
   "metadata": {},
   "source": [
    "### First impression: Looks pretty reasonable, but obviously full of stopwords, thus not pretty useful as it is very \"generic\" for a language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9de5e38e-2e23-4aac-a848-0080cf463179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 95\n",
      "NO TRAIN\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7d8064ec9996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NO TRAIN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n TRAIN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "X_train, y_train = read(\"./HW-10-data/training\")\n",
    "stopwords = read_stopwords()\n",
    "vectorizer4 = CountVectorizer(lowercase =True, stop_words=None, max_df=1.0, min_df=1)\n",
    "X = vectorizer4.fit_transform(X_train)\n",
    "vocab = {v: k for k, v in vectorizer4.vocabulary_.items()}\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42, n_jobs=-1, max_iter=20)\n",
    "results = {}\n",
    "\n",
    "print(\"NO TRAIN\")\n",
    "print(lda.components_)\n",
    "lda.fit(X)\n",
    "print(\"\\n\\n TRAIN\")\n",
    "print(lda.exp_dirichlet_component_)\n",
    "print(lda.components_)\n",
    "for i in range(1,10):\n",
    "    #print(f\"Running iter {i * lda.max_iter}\")\n",
    "    print(\"\\n\\n TRAIN\")\n",
    "    lda.fit(X)\n",
    "    print(lda.exp_dirichlet_component_)\n",
    "    print(lda.components_)\n",
    "    results[i] = get_n_most_likely_words(vocab, lda, 100)\n",
    "        \n",
    "compact = get_compact(results)       \n",
    "calc_overlap(compact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7be2c-f7cb-4672-bb5c-0b04642ea282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "X_train, y_train = read(\"./HW-10-data/training\")\n",
    "stopwords = read_stopwords()\n",
    "vectorizer4 = CountVectorizer(lowercase =True, stop_words=stopwords, max_df=1.0, min_df=1)\n",
    "X = vectorizer4.fit_transform(X_train)\n",
    "vocab = {v: k for k, v in vectorizer4.vocabulary_.items()}\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42, n_jobs=-1, max_iter=20)\n",
    "results = {}\n",
    "for i in range(1,11):\n",
    "    print(f\"Running iter {i * lda.max_iter}\")\n",
    "    lda.fit(X)\n",
    "    results[i] = get_n_most_likely_words(vocab, lda, 100)\n",
    "        \n",
    "compact = get_compact(results)       \n",
    "calc_overlap(compact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f9cfa-97e2-450b-bdd6-9a68ba65fced",
   "metadata": {},
   "source": [
    "### transform data for gibbslda\n",
    "\n",
    "\n",
    "  3.2 Input Data Format\n",
    "\n",
    "  Both data for training/estimating the model and new data (i.e., previously \n",
    "  unseen data) have the same format as follows:\n",
    "\n",
    "    [M]\n",
    "    [document_1]\n",
    "    [document_2]\n",
    "    ...\n",
    "    [document_M]\n",
    "\n",
    "  in which the first line is the total number for documents [M]. Each line \n",
    "  after that is one document. [document_i] is the i^th document of the dataset \n",
    "  that consists of a list of Ni words/terms.\n",
    "\n",
    "    [document_i] = [word_i1] [word_i2] ... [word_iNi]\n",
    "\n",
    "  in which all [word_ij] (i=1..M, j=1..Ni) are text strings and they are \n",
    "  separated by the space character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d680368e-ce0e-40a3-8a16-a27ac45eeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(document, stopwords):\n",
    "    split = document.split(\" \")\n",
    "    cleaned =  [word for word in split if word not in stopwords]\n",
    "    return \" \".join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "473ec58f-d113-41fc-a5c1-4ab6eb64aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length corpus: 95\n",
      "length corpus: 50\n"
     ]
    }
   ],
   "source": [
    "train, _ = read(\"./HW-10-data/training\")\n",
    "test, _ = read(\"./HW-10-data/test\")\n",
    "\n",
    "new_train = []\n",
    "new_test = []\n",
    "for doc in train:\n",
    "    new_train.append(remove_stopwords(doc, stopwords))\n",
    "for doc in test:\n",
    "    new_test.append(remove_stopwords(doc, stopwords))\n",
    "\n",
    "with open(\"lda-input-train.txt\", 'w') as file:\n",
    "    file.write(str(len(train)) + \"\\n\")\n",
    "    for doc in train:\n",
    "        file.write(doc + \"\\n\")\n",
    "        \n",
    "with open(\"lda-input-train-no-stop.txt\", 'w') as file:\n",
    "    file.write(str(len(new_train)) + \"\\n\")\n",
    "    for doc in new_train:\n",
    "        file.write(doc + \"\\n\")\n",
    "        \n",
    "with open(\"lda-input-test.txt\", 'w') as file:\n",
    "    file.write(str(len(test)) + \"\\n\")\n",
    "    for doc in test:\n",
    "        file.write(doc + \"\\n\")\n",
    "with open(\"lda-input-test-no-stop.txt\", 'w') as file:\n",
    "    file.write(str(len(new_test)) + \"\\n\")\n",
    "    for doc in new_test:\n",
    "        file.write(doc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d9f3f-6278-437b-90f2-b204afe393c9",
   "metadata": {},
   "source": [
    "train a model from scratch: GibbsLDA++-0.2/src/lda -est -ntopics 1 -dfile lda-input-train.txt -twords 30 -niters 1000 -dir ./b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ecef3-0756-4ddb-9ac3-32115f03b6d4",
   "metadata": {},
   "source": [
    "twords:  \n",
    "Topic 0th:\n",
    "\t.   0.052836\n",
    "\t,   0.050823\n",
    "\tthe   0.049905\n",
    "\tof   0.025004\n",
    "\tand   0.024430\n",
    "\tto   0.022212\n",
    "\ta   0.018408\n",
    "\tin   0.014462\n",
    "\twas   0.010226\n",
    "\t``   0.008810\n",
    "\tI   0.008008\n",
    "\tthat   0.007665\n",
    "\the   0.007599\n",
    "\tfor   0.006886\n",
    "\twith   0.006570\n",
    "\tit   0.006374\n",
    "\this   0.006352\n",
    "\thad   0.006240\n",
    "\ton   0.005973\n",
    "\tis   0.005421\n",
    "\tbe   0.005349\n",
    "\tThe   0.005269\n",
    "\tas   0.004868\n",
    "\tat   0.004557\n",
    "\tHe   0.004517\n",
    "\tyou   0.004459\n",
    "\ther   0.004405\n",
    "\thim   0.003612\n",
    "\tor   0.003474\n",
    "\tfrom   0.003448"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00727a2b-50f0-41b9-bb42-dfe18bc7b0d2",
   "metadata": {},
   "source": [
    "### interpretation:  \n",
    "LDA tries to infer topics, which are likeli to have generated the documents. As we only use one topic, we trie to infer a topic, that generatet all these documents. This means a model that will show the most frequent word for the documents, \"the most likely\" ones, as these are obviously most \"important\", from a MLE standpoint.  As a topic model, there might be some interesting insights, but in general a simple count would be  sufficient for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62872ee-2433-43c0-baf5-9a5201038235",
   "metadata": {},
   "source": [
    "b) Train an LDA model with GibbsLDA++ with 5 topics (-ntopics) and 200 iterations (-niters) on the\n",
    "training data. Save the model in every 10th iteration (-savestep) and output the 100 most probable\n",
    "words (-twords).\n",
    "For every saved model (model-00010, ..., model-00190, model-final) compute the overlap of words for\n",
    "each topic with its previous model (using the .twords files):  \n",
    "GibbsLDA++-0.2/src/lda -est -ntopics 5 -dfile lda-input-train.txt -twords 100 -niters 200 -savestep 10 -dir ./b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad7f00bb-b258-45ad-a29e-fb672ff64900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_twords(path):\n",
    "    twords = []\n",
    "    for file in os.listdir(path):\n",
    "        if not file.endswith(\"twords\"):\n",
    "            continue\n",
    "        print(f\"Readin {file}\")\n",
    "        curr_file = os.path.join(path, file)\n",
    "        with open(curr_file, 'r') as stream:\n",
    "            content = stream.read()\n",
    "            twords.append(content)\n",
    "    return twords\n",
    "def split_and_remove(list_of_t):\n",
    "    new = []\n",
    "    for t in list_of_t:\n",
    "        new.append(t.split(\"   \")[0])\n",
    "    return new\n",
    "def cleanup_twords(unformatted):\n",
    "    import re\n",
    "    form = unformatted\n",
    "    r = re.compile(\"(Topic)\\s\\d(th):\")\n",
    "    form = re.sub(r, \"NEWTOPIC\", form)\n",
    "    form = re.sub('\\n\\t', \"\\n\", form)\n",
    "    form = form.lstrip(\"\\n\")\n",
    "    form = form.split(\"NEWTOPIC\")\n",
    "    form = [element for element in form if len(element)>0]\n",
    "    form = [element.lstrip(\"\\n\") for element in form if len(element)>0]\n",
    "    form = [element for element in form if len(element)>0]\n",
    "    form = [element.split(\"\\n\") for element in form]\n",
    "    form = [split_and_remove(element) for element in form]            \n",
    "    return form\n",
    "\n",
    "def cleanup_list_of_twords(l_of_t):\n",
    "    n = []\n",
    "    for l in l_of_t:\n",
    "        n.append(cleanup_twords(l))\n",
    "    \n",
    "    # filter remaining empty entry\n",
    "    new = []\n",
    "    for run in n:\n",
    "        new_run = []\n",
    "        for topic in run:\n",
    "            new_run.append([x for x in topic if x])\n",
    "        new.append(new_run)\n",
    "        \n",
    "    return new\n",
    "def compare_runs_via_topics(runs):\n",
    "    \n",
    "    for i in range(len(runs)-1):\n",
    "        print(f\"Comparing run {i+1} with {i+2}\")\n",
    "        for j in range(len(runs[i])):\n",
    "            # compare topic n from run i with run i+1\n",
    "            t1 = runs[i][j]\n",
    "            t2 = runs[i+1][j]\n",
    "            intersec = len([x for x in t1 if x in t2])\n",
    "            print(f\"intersection topic {j} is: {intersec} from 100 topwors ({intersec/100}%)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "18dae42b-dbe0-4031-a041-2ad17402cb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readin model-00010.twords\n",
      "Readin model-00020.twords\n",
      "Readin model-00030.twords\n",
      "Readin model-00040.twords\n",
      "Readin model-00050.twords\n",
      "Readin model-00060.twords\n",
      "Readin model-00070.twords\n",
      "Readin model-00080.twords\n",
      "Readin model-00090.twords\n",
      "Readin model-00100.twords\n",
      "Readin model-00110.twords\n",
      "Readin model-00120.twords\n",
      "Readin model-00130.twords\n",
      "Readin model-00140.twords\n",
      "Readin model-00150.twords\n",
      "Readin model-00160.twords\n",
      "Readin model-00170.twords\n",
      "Readin model-00180.twords\n",
      "Readin model-00190.twords\n",
      "Readin model-00200.twords\n",
      "Readin model-final.twords\n",
      "21\n",
      "5\n",
      "100\n",
      "Comparing run 1 with 2\n",
      "intersection topic 0 is: 76 from 100 topwors (0.76%)\n",
      "intersection topic 1 is: 80 from 100 topwors (0.8%)\n",
      "intersection topic 2 is: 68 from 100 topwors (0.68%)\n",
      "intersection topic 3 is: 86 from 100 topwors (0.86%)\n",
      "intersection topic 4 is: 77 from 100 topwors (0.77%)\n",
      "Comparing run 2 with 3\n",
      "intersection topic 0 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 1 is: 88 from 100 topwors (0.88%)\n",
      "intersection topic 2 is: 78 from 100 topwors (0.78%)\n",
      "intersection topic 3 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 4 is: 88 from 100 topwors (0.88%)\n",
      "Comparing run 3 with 4\n",
      "intersection topic 0 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 1 is: 95 from 100 topwors (0.95%)\n",
      "intersection topic 2 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 3 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 4 is: 88 from 100 topwors (0.88%)\n",
      "Comparing run 4 with 5\n",
      "intersection topic 0 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 1 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 2 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 3 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 4 is: 86 from 100 topwors (0.86%)\n",
      "Comparing run 5 with 6\n",
      "intersection topic 0 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 1 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 2 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 3 is: 95 from 100 topwors (0.95%)\n",
      "intersection topic 4 is: 90 from 100 topwors (0.9%)\n",
      "Comparing run 6 with 7\n",
      "intersection topic 0 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 1 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 2 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 3 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 4 is: 86 from 100 topwors (0.86%)\n",
      "Comparing run 7 with 8\n",
      "intersection topic 0 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 1 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 2 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 3 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 4 is: 89 from 100 topwors (0.89%)\n",
      "Comparing run 8 with 9\n",
      "intersection topic 0 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 1 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 2 is: 86 from 100 topwors (0.86%)\n",
      "intersection topic 3 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 4 is: 90 from 100 topwors (0.9%)\n",
      "Comparing run 9 with 10\n",
      "intersection topic 0 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 1 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 2 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 3 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 4 is: 89 from 100 topwors (0.89%)\n",
      "Comparing run 10 with 11\n",
      "intersection topic 0 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 1 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 2 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 3 is: 96 from 100 topwors (0.96%)\n",
      "intersection topic 4 is: 88 from 100 topwors (0.88%)\n",
      "Comparing run 11 with 12\n",
      "intersection topic 0 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 1 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 2 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 3 is: 97 from 100 topwors (0.97%)\n",
      "intersection topic 4 is: 90 from 100 topwors (0.9%)\n",
      "Comparing run 12 with 13\n",
      "intersection topic 0 is: 95 from 100 topwors (0.95%)\n",
      "intersection topic 1 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 2 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 3 is: 98 from 100 topwors (0.98%)\n",
      "intersection topic 4 is: 89 from 100 topwors (0.89%)\n",
      "Comparing run 13 with 14\n",
      "intersection topic 0 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 1 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 2 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 3 is: 97 from 100 topwors (0.97%)\n",
      "intersection topic 4 is: 92 from 100 topwors (0.92%)\n",
      "Comparing run 14 with 15\n",
      "intersection topic 0 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 1 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 2 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 3 is: 96 from 100 topwors (0.96%)\n",
      "intersection topic 4 is: 91 from 100 topwors (0.91%)\n",
      "Comparing run 15 with 16\n",
      "intersection topic 0 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 1 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 2 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 3 is: 96 from 100 topwors (0.96%)\n",
      "intersection topic 4 is: 88 from 100 topwors (0.88%)\n",
      "Comparing run 16 with 17\n",
      "intersection topic 0 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 1 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 2 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 3 is: 97 from 100 topwors (0.97%)\n",
      "intersection topic 4 is: 89 from 100 topwors (0.89%)\n",
      "Comparing run 17 with 18\n",
      "intersection topic 0 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 1 is: 95 from 100 topwors (0.95%)\n",
      "intersection topic 2 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 3 is: 97 from 100 topwors (0.97%)\n",
      "intersection topic 4 is: 89 from 100 topwors (0.89%)\n",
      "Comparing run 18 with 19\n",
      "intersection topic 0 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 1 is: 96 from 100 topwors (0.96%)\n",
      "intersection topic 2 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 3 is: 95 from 100 topwors (0.95%)\n",
      "intersection topic 4 is: 87 from 100 topwors (0.87%)\n",
      "Comparing run 19 with 20\n",
      "intersection topic 0 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 1 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 2 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 3 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 4 is: 86 from 100 topwors (0.86%)\n",
      "Comparing run 20 with 21\n",
      "intersection topic 0 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 1 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 2 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 3 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 4 is: 100 from 100 topwors (1.0%)\n"
     ]
    }
   ],
   "source": [
    "dir_path=\"./b\"\n",
    "twords_unformatted =read_twords(dir_path)\n",
    "cleanuped = cleanup_list_of_twords(twords_unformatted)\n",
    "print(len(cleanuped)) # 20 runs + final\n",
    "print(len(cleanuped[0])) # 5 topic\n",
    "print(len(cleanuped[0][2])) # 100 twords per topic\n",
    "compare_runs_via_topics(cleanuped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373276d-96a2-4395-bec2-01dc2903114c",
   "metadata": {},
   "source": [
    "Ignoring run 20 + 21 (same model, 100% intersection) it is observable that the topics do converge in terms of topwords at around run 6 and only increases a bit before falling down to the same overlap in the end again. Even though there is a bit variaton for the topics each stays in their \"range\" of intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "01065e8c-6488-49d6-b4a3-284b6e3e6619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readin model-00010.twords\n",
      "Readin model-00020.twords\n",
      "Readin model-00030.twords\n",
      "Readin model-00040.twords\n",
      "Readin model-00050.twords\n",
      "Readin model-00060.twords\n",
      "Readin model-00070.twords\n",
      "Readin model-00080.twords\n",
      "Readin model-00090.twords\n",
      "Readin model-00100.twords\n",
      "Readin model-00110.twords\n",
      "Readin model-00120.twords\n",
      "Readin model-00130.twords\n",
      "Readin model-00140.twords\n",
      "Readin model-00150.twords\n",
      "Readin model-00160.twords\n",
      "Readin model-00170.twords\n",
      "Readin model-00180.twords\n",
      "Readin model-00190.twords\n",
      "Readin model-00200.twords\n",
      "Readin model-final.twords\n",
      "21\n",
      "5\n",
      "100\n",
      "Comparing run 1 with 2\n",
      "intersection topic 0 is: 47 from 100 topwors (0.47%)\n",
      "intersection topic 1 is: 72 from 100 topwors (0.72%)\n",
      "intersection topic 2 is: 71 from 100 topwors (0.71%)\n",
      "intersection topic 3 is: 79 from 100 topwors (0.79%)\n",
      "intersection topic 4 is: 52 from 100 topwors (0.52%)\n",
      "Comparing run 2 with 3\n",
      "intersection topic 0 is: 65 from 100 topwors (0.65%)\n",
      "intersection topic 1 is: 74 from 100 topwors (0.74%)\n",
      "intersection topic 2 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 3 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 4 is: 67 from 100 topwors (0.67%)\n",
      "Comparing run 3 with 4\n",
      "intersection topic 0 is: 65 from 100 topwors (0.65%)\n",
      "intersection topic 1 is: 74 from 100 topwors (0.74%)\n",
      "intersection topic 2 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 3 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 4 is: 74 from 100 topwors (0.74%)\n",
      "Comparing run 4 with 5\n",
      "intersection topic 0 is: 71 from 100 topwors (0.71%)\n",
      "intersection topic 1 is: 77 from 100 topwors (0.77%)\n",
      "intersection topic 2 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 3 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 4 is: 75 from 100 topwors (0.75%)\n",
      "Comparing run 5 with 6\n",
      "intersection topic 0 is: 83 from 100 topwors (0.83%)\n",
      "intersection topic 1 is: 82 from 100 topwors (0.82%)\n",
      "intersection topic 2 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 3 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 4 is: 76 from 100 topwors (0.76%)\n",
      "Comparing run 6 with 7\n",
      "intersection topic 0 is: 73 from 100 topwors (0.73%)\n",
      "intersection topic 1 is: 88 from 100 topwors (0.88%)\n",
      "intersection topic 2 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 3 is: 88 from 100 topwors (0.88%)\n",
      "intersection topic 4 is: 82 from 100 topwors (0.82%)\n",
      "Comparing run 7 with 8\n",
      "intersection topic 0 is: 74 from 100 topwors (0.74%)\n",
      "intersection topic 1 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 2 is: 95 from 100 topwors (0.95%)\n",
      "intersection topic 3 is: 84 from 100 topwors (0.84%)\n",
      "intersection topic 4 is: 81 from 100 topwors (0.81%)\n",
      "Comparing run 8 with 9\n",
      "intersection topic 0 is: 79 from 100 topwors (0.79%)\n",
      "intersection topic 1 is: 83 from 100 topwors (0.83%)\n",
      "intersection topic 2 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 3 is: 83 from 100 topwors (0.83%)\n",
      "intersection topic 4 is: 81 from 100 topwors (0.81%)\n",
      "Comparing run 9 with 10\n",
      "intersection topic 0 is: 77 from 100 topwors (0.77%)\n",
      "intersection topic 1 is: 86 from 100 topwors (0.86%)\n",
      "intersection topic 2 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 3 is: 83 from 100 topwors (0.83%)\n",
      "intersection topic 4 is: 85 from 100 topwors (0.85%)\n",
      "Comparing run 10 with 11\n",
      "intersection topic 0 is: 79 from 100 topwors (0.79%)\n",
      "intersection topic 1 is: 84 from 100 topwors (0.84%)\n",
      "intersection topic 2 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 3 is: 83 from 100 topwors (0.83%)\n",
      "intersection topic 4 is: 86 from 100 topwors (0.86%)\n",
      "Comparing run 11 with 12\n",
      "intersection topic 0 is: 77 from 100 topwors (0.77%)\n",
      "intersection topic 1 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 2 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 3 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 4 is: 85 from 100 topwors (0.85%)\n",
      "Comparing run 12 with 13\n",
      "intersection topic 0 is: 78 from 100 topwors (0.78%)\n",
      "intersection topic 1 is: 88 from 100 topwors (0.88%)\n",
      "intersection topic 2 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 3 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 4 is: 82 from 100 topwors (0.82%)\n",
      "Comparing run 13 with 14\n",
      "intersection topic 0 is: 74 from 100 topwors (0.74%)\n",
      "intersection topic 1 is: 86 from 100 topwors (0.86%)\n",
      "intersection topic 2 is: 93 from 100 topwors (0.93%)\n",
      "intersection topic 3 is: 86 from 100 topwors (0.86%)\n",
      "intersection topic 4 is: 81 from 100 topwors (0.81%)\n",
      "Comparing run 14 with 15\n",
      "intersection topic 0 is: 81 from 100 topwors (0.81%)\n",
      "intersection topic 1 is: 88 from 100 topwors (0.88%)\n",
      "intersection topic 2 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 3 is: 86 from 100 topwors (0.86%)\n",
      "intersection topic 4 is: 81 from 100 topwors (0.81%)\n",
      "Comparing run 15 with 16\n",
      "intersection topic 0 is: 77 from 100 topwors (0.77%)\n",
      "intersection topic 1 is: 90 from 100 topwors (0.9%)\n",
      "intersection topic 2 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 3 is: 88 from 100 topwors (0.88%)\n",
      "intersection topic 4 is: 82 from 100 topwors (0.82%)\n",
      "Comparing run 16 with 17\n",
      "intersection topic 0 is: 78 from 100 topwors (0.78%)\n",
      "intersection topic 1 is: 85 from 100 topwors (0.85%)\n",
      "intersection topic 2 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 3 is: 84 from 100 topwors (0.84%)\n",
      "intersection topic 4 is: 81 from 100 topwors (0.81%)\n",
      "Comparing run 17 with 18\n",
      "intersection topic 0 is: 77 from 100 topwors (0.77%)\n",
      "intersection topic 1 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 2 is: 92 from 100 topwors (0.92%)\n",
      "intersection topic 3 is: 87 from 100 topwors (0.87%)\n",
      "intersection topic 4 is: 82 from 100 topwors (0.82%)\n",
      "Comparing run 18 with 19\n",
      "intersection topic 0 is: 73 from 100 topwors (0.73%)\n",
      "intersection topic 1 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 2 is: 91 from 100 topwors (0.91%)\n",
      "intersection topic 3 is: 84 from 100 topwors (0.84%)\n",
      "intersection topic 4 is: 82 from 100 topwors (0.82%)\n",
      "Comparing run 19 with 20\n",
      "intersection topic 0 is: 78 from 100 topwors (0.78%)\n",
      "intersection topic 1 is: 89 from 100 topwors (0.89%)\n",
      "intersection topic 2 is: 94 from 100 topwors (0.94%)\n",
      "intersection topic 3 is: 83 from 100 topwors (0.83%)\n",
      "intersection topic 4 is: 82 from 100 topwors (0.82%)\n",
      "Comparing run 20 with 21\n",
      "intersection topic 0 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 1 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 2 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 3 is: 100 from 100 topwors (1.0%)\n",
      "intersection topic 4 is: 100 from 100 topwors (1.0%)\n"
     ]
    }
   ],
   "source": [
    "# repeat without stopwords\n",
    "#GibbsLDA++-0.2/src/lda -est -ntopics 5 -dfile lda-input-train-no-stop.txt -twords 100 -niters 200 -savestep 10 -dir ./s\n",
    "\n",
    "dir_path=\"./s\"\n",
    "twords_unformatted =read_twords(dir_path)\n",
    "cleanuped = cleanup_list_of_twords(twords_unformatted)\n",
    "print(len(cleanuped)) # 20 runs + final\n",
    "print(len(cleanuped[0])) # 5 topic\n",
    "print(len(cleanuped[0][2])) # 100 twords per topic\n",
    "compare_runs_via_topics(cleanuped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c07631-cbc8-4a41-b8ac-ccae7bbebad2",
   "metadata": {},
   "source": [
    "Even though the overlap is siginficantly lower, the situation is prerry similar: after a few runs, the oerlap converges for every topic in a specific range for this topic, maybe 1-2 laps later as in the first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7081e43-554b-435c-8c3b-29199d1661b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference in test\n",
    "#GibbsLDA++-0.2/src/lda -inf -niters 100 -twords 30 -dir ./ -model ./s/model-final \\-dfile lda-input-test.txt\n",
    "# final model: the final model without stopwords, input with stopwords\n",
    "\n",
    "#GibbsLDA++-0.2/src/lda -inf -niters 100 -twords 30 -dir ./ -model ./s/model-final \\-dfile lda-input-test-no-stop.txt\n",
    "# final model without stopwords input without\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b314b-3f38-45ae-ab39-1de7d0ad45bd",
   "metadata": {},
   "source": [
    "The inference works ( visible in .tassign) as the inference removes unknown words itself. The overlap is far better using both models with stopwords, but that doesn't mean the topics are better, as they tend to be more \"generic\" as explained before, because stopwords make the important part of the topics. A model trained with topwords and inference without stopwords is the worst one, because we generate topics based on wordcounts and remove the most likeli words. Thus, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
