{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.2 Language Models\n",
    "First lets read the data from the given -train and .test files respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 \n",
      " Example#43:  %^% %^% \" Der Werbe-Job begann mich zu langweilen , also schrieb ich wieder . \" %$% %$%\n",
      "50000 \n",
      " Example#43:  %^% %^% Er studierte am Southern California Institute of Architecture und bei John Hejduk an der Cooper Union in New York . 1985 gr端ndete er sein eigenes B端ro in Tokio . %$% %$%\n"
     ]
    }
   ],
   "source": [
    "START_SYMBOL = '%^% %^%'\n",
    "END_SYMBOL = '%$% %$%'\n",
    "\n",
    "# read train and test files\n",
    "with open('de_text/de_text.train') as f:\n",
    "    train_sentences = [line.rstrip() for line in f]\n",
    "with open('de_text/de_text.test') as f:\n",
    "    test_sentences = [line.rstrip() for line in f]\n",
    "    \n",
    "print(f'{len(train_sentences)} \\n Example#43:  {train_sentences[43]}')\n",
    "print(f'{len(test_sentences)} \\n Example#43:  {test_sentences[43]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 \n",
      " Example#43:  ['``', 'der', 'werbe-job', 'begann', 'mich', 'zu', 'langweilen', ',', 'also', 'schrieb', 'ich', 'wieder', '.', '``']\n",
      "50000 \n",
      " Example#43:  ['er', 'studierte', 'am', 'southern', 'california', 'institute', 'of', 'architecture', 'und', 'bei', 'john', 'hejduk', 'an', 'der', 'cooper', 'union', 'in', 'new', 'york', '.', '1985', 'gr端ndete', 'er', 'sein', 'eigenes', 'b端ro', 'in', 'tokio', '.']\n"
     ]
    }
   ],
   "source": [
    "# for unigram: omit START and END symbols\n",
    "train_sentences_unigram = [line.lstrip(START_SYMBOL).rstrip(END_SYMBOL) for line in train_sentences]\n",
    "test_sentences_unigram = [line.lstrip(START_SYMBOL).rstrip(END_SYMBOL) for line in test_sentences]\n",
    "\n",
    "# tokenize sentences, lowercase each word -> list of lists\n",
    "tokenized_train_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sentence))) for sentence in train_sentences_unigram]\n",
    "tokenized_test_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sentence))) for sentence in test_sentences_unigram]\n",
    "\n",
    "print(f'{len(tokenized_train_text)} \\n Example#43:  {tokenized_train_text[43]}')\n",
    "print(f'{len(tokenized_test_text)} \\n Example#43:  {tokenized_test_text[43]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) List the 20 most frequent words from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigrams: 911850\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import ngrams, FreqDist\n",
    "\n",
    "list_unigrams = [ngrams(sentence, 1) for sentence in tokenized_train_text]\n",
    "# unpack list of lists\n",
    "text_unigrams = [item for sublist in list_unigrams for item in sublist]\n",
    "print(f'Number of unigrams: {len(text_unigrams)}')\n",
    "\n",
    "frequency_dist = FreqDist(text_unigrams)\n",
    "unigram_dict = dict()\n",
    "for key, value in frequency_dist.items():\n",
    "        unigram_dict[' '.join(key)] = value\n",
    "        \n",
    "unigram_freq = pd.Series(unigram_dict).nlargest(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Compute the percentage of tokens in the test data that have not been seen in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigrams in test-data: 907335\n",
      "Number token in test, but not in training: 67300\n",
      "\n",
      "Percentage not seen in train: 0.07417326566262736\n"
     ]
    }
   ],
   "source": [
    "def diff(first, second):\n",
    "    second = set(second)\n",
    "    return [item for item in first if item not in second]\n",
    "\n",
    "# text_unigrams = text_unigrams_train\n",
    "list_unigrams_test = [ngrams(sentence, 1) for sentence in tokenized_test_text]\n",
    "# unpack list of lists\n",
    "text_unigrams_test = [item for sublist in list_unigrams_test for item in sublist]\n",
    "print(f'Number of unigrams in test-data: {len(text_unigrams_test)}')\n",
    "\n",
    "unigrams_in_test_but_not_in_train = diff(text_unigrams_test, text_unigrams)\n",
    "print(f'Number token in test, but not in training: {len(unigrams_in_test_but_not_in_train)}')\n",
    "print(f'\\nPercentage not seen in train: {len(unigrams_in_test_but_not_in_train) / len(text_unigrams_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) List the 20 most frequent bigrams from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bigrams: 961850\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_bigrams = [ngrams(sentence, 2, \n",
    "                       pad_left=True, \n",
    "                       pad_right=True, \n",
    "                       left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                       right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                for sentence in tokenized_train_text]\n",
    "# unpack list of lists\n",
    "text_bigrams = [item for sublist in list_bigrams for item in sublist]\n",
    "print(f'Number of bigrams: {len(text_bigrams)}')\n",
    "\n",
    "frequency_dist = FreqDist(text_bigrams)\n",
    "bigram_dict = dict()\n",
    "for key, value in frequency_dist.items():\n",
    "        bigram_dict[' '.join(key)] = value\n",
    "        \n",
    "bigram_freq = pd.Series(bigram_dict).nlargest(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Compute the percentage of bigrams in the test data that have not been seen in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bigrams in test-data: 957335\n",
      "Number token in test, but not in training: 391930\n",
      "\n",
      "Percentage not seen in train: 0.40939691957360796\n"
     ]
    }
   ],
   "source": [
    "list_bigrams_test = [ngrams(sentence, 2, \n",
    "                            pad_left=True, \n",
    "                            pad_right=True, \n",
    "                            left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                            right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                    for sentence in tokenized_test_text]\n",
    "# unpack list of lists\n",
    "text_bigrams_test = [item for sublist in list_bigrams_test for item in sublist]\n",
    "print(f'Number of bigrams in test-data: {len(text_bigrams_test)}')\n",
    "\n",
    "bigrams_in_test_but_not_in_train = diff(text_bigrams_test, text_bigrams)\n",
    "print(f'Number token in test, but not in training: {len(bigrams_in_test_but_not_in_train)}')\n",
    "print(f'\\nPercentage not seen in train: {len(bigrams_in_test_but_not_in_train) / len(text_bigrams_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Compute the percentage of trigrams in the test data that have not been seen in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trigrams in train-data: 1011850\n",
      "Number of trigrams in test-data: 1007335\n",
      "Number token in test, but not in training: 715001\n",
      "\n",
      "Percentage not seen in train: 0.7097946561967965\n"
     ]
    }
   ],
   "source": [
    "list_trigrams = [ngrams(sentence, 3,\n",
    "                        pad_left=True, \n",
    "                        pad_right=True, \n",
    "                        left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                        right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                for sentence in tokenized_train_text]\n",
    "\n",
    "list_trigrams_test = [ngrams(sentence, 3, \n",
    "                            pad_left=True, \n",
    "                            pad_right=True, \n",
    "                            left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                            right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                    for sentence in tokenized_test_text]\n",
    "# unpack list of lists\n",
    "text_trigrams = [item for sublist in list_trigrams for item in sublist]\n",
    "text_trigrams_test = [item for sublist in list_trigrams_test for item in sublist]\n",
    "print(f'Number of trigrams in train-data: {len(text_trigrams)}')\n",
    "print(f'Number of trigrams in test-data: {len(text_trigrams_test)}')\n",
    "\n",
    "trigrams_in_test_but_not_in_train = diff(text_trigrams_test, text_trigrams)\n",
    "print(f'Number token in test, but not in training: {len(trigrams_in_test_but_not_in_train)}')\n",
    "print(f'\\nPercentage not seen in train: {len(trigrams_in_test_but_not_in_train) / len(text_trigrams_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) How many sentences in the test data are estimated to have zero probability by an MLE bigram model from the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "* each sentence of the test data that has at least one bigram, which does not occur in the training data (creating prob. of zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE Estimates: [(('ebbe', ('<s>',)), 0.0), (('in', ('ebbe',)), 0.0), (('der', ('in',)), 0.19108627504429604), (('staatskasse', ('der',)), 3.556061306496924e-05), (('/', ('staatskasse',)), 0.0), (('/', ('/',)), 0.1574074074074074), (('im', ('/',)), 0.0), (('ersten', ('im',)), 0.01425914445133292), (('halbjahr', ('ersten',)), 0.05723905723905724), (('diesen', ('halbjahr',)), 0.0), (('jahres', ('diesen',)), 0.012232415902140673), (('sank', ('jahres',)), 0.0), (('das', ('sank',)), 0.0), (('steueraufkommen', ('das',)), 0.00022119000221190003), (('(', ('steueraufkommen',)), 0.0), (('ohne', ('(',)), 0.0017205781142463868), (('gemeindesteuern', ('ohne',)), 0.0), ((')', ('gemeindesteuern',)), 0), (('gegen端ber', (')',)), 0.0003443526170798898), (('dem', ('gegen端ber',)), 0.21634615384615385), (('gleichen', ('dem',)), 0.0013608087091757388), (('zeitraum', ('gleichen',)), 0.07547169811320754), (('des', ('zeitraum',)), 0.09090909090909091), (('vorjahresum', ('des',)), 0.0), (('5,2', ('vorjahresum',)), 0), (('prozent', ('5,2',)), 0.0), (('.', ('prozent',)), 0.11497730711043873), (('</s>', ('.',)), 0.0)]\n",
      "\n",
      "Number of sentences in test with zero prob: 49999\n"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm import Vocabulary\n",
    "\n",
    "n = 2\n",
    "train_data = [bigrams(t,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"<e>\") for t in tokenized_train_text]\n",
    "words = [word for sent in tokenized_train_text for word in sent]\n",
    "words.extend([\"<s>\", \"<e>\"])\n",
    "padded_vocab = Vocabulary(words)\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_vocab)\n",
    "\n",
    "### TEST ###\n",
    "\n",
    "test_data = [bigrams(t,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\") for t in tokenized_test_text]\n",
    "for test in test_data[1:2]:\n",
    "    print (\"MLE Estimates:\", [((ngram[-1], ngram[:-1]),model.score(ngram[-1], ngram[:-1])) for ngram in test])\n",
    "\n",
    "zero_prob_sentences = []\n",
    "for bigram_sent in test_data:\n",
    "    for bigram in bigram_sent:\n",
    "        if model.score(bigram[-1], bigram[:-1]) == 0.0:\n",
    "            zero_prob_sentences.append((bigram_sent, bigram))\n",
    "            break # only count once\n",
    "            \n",
    "print(f'\\nNumber of sentences in test with zero prob: {len(zero_prob_sentences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Give the probabilities of the first 3 sentences from the test data, using a linear combination of 0-gram, unigram, bigram and trigram model with $\\lambda_0 = 1.0 x 10^{-10}$; $\\lambda_1 = 0.01$; $\\lambda_2 = 0.2$; $\\lambda_3 = 1-(\\lambda_0 + \\lambda_1 + \\lambda_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-3fceb7403a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#    for n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#print(\"Unigram:\", np.prod([unigram_model.score(unigram) for unigram in test_data_unigram[0]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bigram:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbigram_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data_bigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-113-3fceb7403a7d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#    for n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#print(\"Unigram:\", np.prod([unigram_model.score(unigram) for unigram in test_data_unigram[0]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bigram:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbigram_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data_bigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk import bigrams, trigrams\n",
    "\n",
    "lambda_0 = 10**(-10)\n",
    "lambda_1 = 0.01\n",
    "lambda_2 = 0.2\n",
    "lambda_3 = 1.0 - (lambda_0 + lambda_1 + lambda_2)\n",
    "\n",
    "### TRAIN ###\n",
    "\n",
    "#train_data_unigram = [ngrams(sentence, 1) for sentence in tokenized_train_text]\n",
    "\n",
    "train_data_unigram, padded_vocab = padded_everygram_pipeline(1, tokenized_train_text) # n = 1\n",
    "\n",
    "train_data_bigram = [bigrams(t,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"<e>\") for t in tokenized_train_text]\n",
    "train_data_trigram = [ngrams(sentence, 3,\n",
    "                        pad_left=True, \n",
    "                        pad_right=True, \n",
    "                        left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                        right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                for sentence in tokenized_train_text]\n",
    "words = [word for sent in tokenized_train_text for word in sent]\n",
    "padded_vocab = Vocabulary(words.extend([\"<s>\", \"<e>\"]))\n",
    "unigram_model = MLE(1).fit(train_data_unigram, padded_vocab) # n = 1\n",
    "bigram_model = MLE(2).fit(train_data_bigram, padded_vocab)\n",
    "trigram_model = MLE(3).fit(train_data_trigram, padded_vocab)\n",
    "\n",
    "### TEST ###\n",
    "\n",
    "#test_data_unigram = [ngrams(sentence, 1) for sentence in tokenized_test_text]\n",
    "test_data_unigram, _ = padded_everygram_pipeline(1, tokenized_test_text) # n = 1\n",
    "test_data_bigram = [ngrams(sentence, 2, \n",
    "                       pad_left=True, \n",
    "                       pad_right=True, \n",
    "                       left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                       right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                for sentence in tokenized_test_text]\n",
    "test_data_trigram = [ngrams(sentence, 3,\n",
    "                        pad_left=True, \n",
    "                        pad_right=True, \n",
    "                        left_pad_symbol='<s>', # as we removed start symbol, replace by <s> for plotting reasons\n",
    "                        right_pad_symbol='<e>') # as we removed end symbol, replace by <e> for plotting reasons\n",
    "                for sentence in tokenized_test_text]\n",
    "\n",
    "#for test in test_data[:3]:\n",
    "#    for n\n",
    "#print(\"Unigram:\", np.prod([unigram_model.score(unigram) for unigram in test_data_unigram[0]]))\n",
    "print(\"Bigram:\", np.prod([bigram_model.score(bigram[-1], bigram[:-1]) for bigram in test_data_bigram[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
